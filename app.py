import streamlit as st
import pandas as pd
import numpy as np
import re
from io import StringIO
import chardet
from urllib.parse import urlparse
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Configuration de la page
st.set_page_config(
    page_title="Outil d'Analyse Netlinking SEO",
    page_icon="ğŸ”—",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ”— Outil d'Analyse Netlinking SEO")
st.markdown("**Priorisez vos campagnes de netlinking en croisant les donnÃ©es Ahrefs et GSC**")

# Fonctions utilitaires
def detect_encoding(file_content):
    """DÃ©tecte l'encodage d'un fichier"""
    detected = chardet.detect(file_content)
    return detected['encoding'] if detected['confidence'] > 0.7 else 'utf-8'

def read_ahrefs_csv(uploaded_file):
    """Lit un fichier CSV Ahrefs avec gestion des encodages"""
    try:
        # Lire le contenu brut
        content = uploaded_file.read()
        
        # Essayer UTF-16 LE (format Ahrefs typique)
        try:
            decoded_content = content.decode('utf-16le')
            # Nettoyer les caractÃ¨res nuls
            decoded_content = decoded_content.replace('\x00', '')
            # Supprimer BOM
            decoded_content = decoded_content.replace('\ufeff', '')
            df = pd.read_csv(StringIO(decoded_content), sep='\t')
            return df
        except:
            pass
        
        # Essayer UTF-8
        try:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='utf-8', sep='\t')
            return df
        except:
            pass
        
        # Essayer dÃ©tection automatique
        encoding = detect_encoding(content)
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding=encoding, sep='\t')
        return df
        
    except Exception as e:
        st.error(f"Erreur lors de la lecture du fichier : {str(e)}")
        return None

def extract_domain(url):
    """Extrait le domaine d'une URL"""
    try:
        return urlparse(url).netloc.lower().replace('www.', '')
    except:
        return url

def clean_percentage(value):
    """Nettoie les pourcentages"""
    if isinstance(value, str):
        return float(value.replace('%', '').replace(',', '.'))
    return value

def calculate_thematic_relevance(domain_or_url, keywords_data, pages_data):
    """Calcule la pertinence thÃ©matique d'un domaine/URL"""
    relevance_score = 0
    
    # Extraire les mots-clÃ©s du domaine/URL
    domain_words = re.findall(r'\w+', domain_or_url.lower())
    
    # Comparer avec les mots-clÃ©s stratÃ©giques
    if keywords_data is not None:
        for _, row in keywords_data.iterrows():
            keyword = str(row.get('Keyword', '')).lower()
            keyword_words = re.findall(r'\w+', keyword)
            
            # Calculer la similaritÃ©
            common_words = set(domain_words) & set(keyword_words)
            if common_words:
                relevance_score += len(common_words) * row.get('Search Volume', 0) / 1000
    
    # Comparer avec les pages performantes GSC
    if pages_data is not None:
        for _, row in pages_data.iterrows():
            page_url = str(row.get('Pages les plus populaires', '')).lower()
            page_words = re.findall(r'\w+', page_url)
            
            common_words = set(domain_words) & set(page_words)
            if common_words:
                relevance_score += len(common_words) * row.get('Clics', 0) / 100
    
    return min(relevance_score, 100)  # Plafonner Ã  100

def calculate_priority_score(row, keywords_data=None, pages_data=None):
    """Calcule le score de prioritÃ© pour un backlink"""
    
    # MÃ©triques de base
    dr = float(row.get('Domain rating', 0))
    traffic = float(row.get('Domain traffic', 0)) if pd.notna(row.get('Domain traffic', 0)) else 0
    
    # Calcul du gap concurrentiel (nombre de concurrents qui reÃ§oivent des liens)
    competitor_columns = [col for col in row.index if col.startswith('www.') and col != 'www.explore-grandest.com/']
    gap_score = 0
    for col in competitor_columns:
        if pd.notna(row[col]) and int(row[col]) > 0:
            gap_score += 1
    
    # Normaliser le gap (sur 100)
    gap_normalized = (gap_score / len(competitor_columns)) * 100 if competitor_columns else 0
    
    # Calcul de la pertinence thÃ©matique
    domain = row.get('Domain', '')
    thematic_score = calculate_thematic_relevance(domain, keywords_data, pages_data)
    
    # Score final avec pondÃ©ration
    priority_score = (
        dr * 0.2 +  # Domain Rating (20%)
        min(traffic / 10000, 100) * 0.2 +  # Traffic normalisÃ© (20%)
        gap_normalized * 0.3 +  # Gap concurrentiel (30%)
        thematic_score * 0.3  # Pertinence thÃ©matique (30%)
    )
    
    return round(priority_score, 2)

# Interface utilisateur
st.sidebar.header("ğŸ“ Upload des fichiers")

# Upload des fichiers
ahrefs_domains_file = st.sidebar.file_uploader(
    "Export Ahrefs - Referring Domains",
    type=['csv'],
    help="Export CSV des domaines rÃ©fÃ©rents depuis Ahrefs"
)

ahrefs_pages_file = st.sidebar.file_uploader(
    "Export Ahrefs - Referring Pages",
    type=['csv'],
    help="Export CSV des pages rÃ©fÃ©rentes depuis Ahrefs"
)

gsc_keywords_file = st.sidebar.file_uploader(
    "Export GSC - RequÃªtes",
    type=['csv'],
    help="Export CSV des requÃªtes depuis Google Search Console"
)

gsc_pages_file = st.sidebar.file_uploader(
    "Export GSC - Pages",
    type=['csv'],
    help="Export CSV des pages depuis Google Search Console"
)

strategic_keywords_file = st.sidebar.file_uploader(
    "Mots-clÃ©s stratÃ©giques",
    type=['xlsx', 'csv'],
    help="Fichier Excel ou CSV contenant vos mots-clÃ©s stratÃ©giques"
)

serp_data_file = st.sidebar.file_uploader(
    "Export SERPs (Optionnel)",
    type=['xlsx', 'csv'],
    help="DonnÃ©es des SERPs pour les mots-clÃ©s stratÃ©giques"
)

# ParamÃ¨tres de filtrage
st.sidebar.header("ğŸ›ï¸ ParamÃ¨tres de filtrage")

# Charger et traiter les donnÃ©es
if ahrefs_domains_file is not None:
    
    # Lecture du fichier Ahrefs Domains
    with st.spinner("Chargement des donnÃ©es Ahrefs Domains..."):
        ahrefs_domains_df = read_ahrefs_csv(ahrefs_domains_file)
    
    if ahrefs_domains_df is not None:
        st.success(f"âœ… Fichier Ahrefs Domains chargÃ© : {len(ahrefs_domains_df)} domaines")
        
        # Identifier les colonnes des concurrents
        competitor_columns = [col for col in ahrefs_domains_df.columns if col.startswith('www.')]
        main_site = 'www.explore-grandest.com/' if 'www.explore-grandest.com/' in competitor_columns else competitor_columns[0]
        other_competitors = [col for col in competitor_columns if col != main_site]
        
        st.sidebar.write(f"**Site principal dÃ©tectÃ© :** {main_site}")
        st.sidebar.write(f"**Concurrents dÃ©tectÃ©s :** {len(other_competitors)}")
        
        # Filtre par nombre de concurrents
        max_competitors = len(other_competitors)
        min_competitors_filter = st.sidebar.slider(
            "Minimum de concurrents ayant des liens",
            min_value=1,
            max_value=max_competitors,
            value=1,
            help="Filtrer les domaines qui font des liens vers au moins X concurrents"
        )
        
        # Filtres sur les mÃ©triques
        st.sidebar.subheader("Filtres sur les mÃ©triques")
        
        min_dr = st.sidebar.slider(
            "Domain Rating minimum",
            min_value=0,
            max_value=100,
            value=20,
            help="Filtrer par Domain Rating minimum"
        )
        
        min_traffic = st.sidebar.number_input(
            "Trafic minimum",
            min_value=0,
            value=1000,
            help="Filtrer par trafic minimum du domaine"
        )
        
        # Charger les autres fichiers pour l'analyse thÃ©matique
        keywords_data = None
        pages_data = None
        serp_data = None
        
        if strategic_keywords_file is not None:
            if strategic_keywords_file.name.endswith('.xlsx'):
                keywords_data = pd.read_excel(strategic_keywords_file)
            else:
                keywords_data = pd.read_csv(strategic_keywords_file)
            st.success(f"âœ… Mots-clÃ©s stratÃ©giques chargÃ©s : {len(keywords_data)} mots-clÃ©s")
        
        if gsc_pages_file is not None:
            pages_data = pd.read_csv(gsc_pages_file)
            # Nettoyer les donnÃ©es GSC
            if 'CTR' in pages_data.columns:
                pages_data['CTR'] = pages_data['CTR'].apply(clean_percentage)
            st.success(f"âœ… Pages GSC chargÃ©es : {len(pages_data)} pages")
        
        if gsc_keywords_file is not None:
            gsc_keywords_data = pd.read_csv(gsc_keywords_file)
            if 'CTR' in gsc_keywords_data.columns:
                gsc_keywords_data['CTR'] = gsc_keywords_data['CTR'].apply(clean_percentage)
            st.success(f"âœ… RequÃªtes GSC chargÃ©es : {len(gsc_keywords_data)} requÃªtes")
        
        if serp_data_file is not None:
            if serp_data_file.name.endswith('.xlsx'):
                serp_data = pd.read_excel(serp_data_file)
            else:
                serp_data = pd.read_csv(serp_data_file)
            st.success(f"âœ… DonnÃ©es SERPs chargÃ©es : {len(serp_data)} entrÃ©es")
        
        # Appliquer les filtres
        with st.spinner("Application des filtres et calcul des scores..."):
            filtered_df = ahrefs_domains_df.copy()
            
            # Convertir les colonnes numÃ©riques
            filtered_df['Domain rating'] = pd.to_numeric(filtered_df['Domain rating'], errors='coerce')
            filtered_df['Domain traffic'] = pd.to_numeric(filtered_df['Domain traffic'], errors='coerce')
            
            # Filtre DR
            filtered_df = filtered_df[filtered_df['Domain rating'] >= min_dr]
            
            # Filtre trafic
            filtered_df = filtered_df[filtered_df['Domain traffic'] >= min_traffic]
            
            # Filtre nombre de concurrents
            def count_competitor_links(row):
                count = 0
                for col in other_competitors:
                    if pd.notna(row[col]) and int(row[col]) > 0:
                        count += 1
                return count
            
            filtered_df['competitor_links_count'] = filtered_df.apply(count_competitor_links, axis=1)
            filtered_df = filtered_df[filtered_df['competitor_links_count'] >= min_competitors_filter]
            
            # Calculer les scores de prioritÃ©
            filtered_df['priority_score'] = filtered_df.apply(
                lambda row: calculate_priority_score(row, keywords_data, pages_data), 
                axis=1
            )
            
            # Trier par score de prioritÃ©
            filtered_df = filtered_df.sort_values('priority_score', ascending=False)
            
            # Ajouter des mÃ©triques calculÃ©es
            filtered_df['gap_opportunity'] = filtered_df['competitor_links_count']
            filtered_df['traffic_potential'] = filtered_df['Domain traffic'] * filtered_df['Domain rating'] / 100
        
        # Affichage des rÃ©sultats
        st.header("ğŸ“Š RÃ©sultats de l'analyse")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Domaines analysÃ©s",
                len(ahrefs_domains_df),
                delta=f"+{len(filtered_df)} aprÃ¨s filtrage"
            )
        
        with col2:
            avg_dr = filtered_df['Domain rating'].mean()
            st.metric(
                "DR moyen",
                f"{avg_dr:.1f}",
                delta=f"Min: {min_dr}"
            )
        
        with col3:
            avg_gap = filtered_df['competitor_links_count'].mean()
            st.metric(
                "Gap moyen",
                f"{avg_gap:.1f}",
                delta=f"concurrents/domaine"
            )
        
        with col4:
            total_traffic = filtered_df['Domain traffic'].sum()
            st.metric(
                "Trafic total potentiel",
                f"{total_traffic/1000000:.1f}M",
                delta="visiteurs/mois"
            )
        
        # Graphiques
        st.subheader("ğŸ“ˆ Visualisations")
        
        # Graphique scatter plot
        fig_scatter = px.scatter(
            filtered_df.head(50),
            x='Domain rating',
            y='Domain traffic',
            size='priority_score',
            color='competitor_links_count',
            hover_data=['Domain', 'priority_score', 'gap_opportunity'],
            title="Top 50 - OpportunitÃ©s de Netlinking",
            labels={
                'Domain rating': 'Domain Rating',
                'Domain traffic': 'Trafic du Domaine',
                'competitor_links_count': 'Nombre de concurrents'
            }
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
        
        # Graphique en barres des top domaines
        top_domains = filtered_df.head(20)
        fig_bar = px.bar(
            top_domains,
            x='priority_score',
            y='Domain',
            orientation='h',
            title="Top 20 - Domaines par Score de PrioritÃ©",
            labels={'priority_score': 'Score de PrioritÃ©', 'Domain': 'Domaine'}
        )
        fig_bar.update_layout(yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig_bar, use_container_width=True)
        
        # Tableau dÃ©taillÃ©
        st.subheader("ğŸ“‹ Tableau dÃ©taillÃ© des opportunitÃ©s")
        
        # SÃ©lectionner les colonnes Ã  afficher
        display_columns = [
            'Domain', 'Domain rating', 'Domain traffic', 'priority_score',
            'competitor_links_count', 'gap_opportunity'
        ] + other_competitors[:3]  # Afficher les 3 premiers concurrents
        
        display_df = filtered_df[display_columns].head(100)
        
        # Formatter le tableau
        display_df = display_df.round(2)
        display_df.columns = [
            'Domaine', 'DR', 'Trafic', 'Score PrioritÃ©',
            'Nb Concurrents', 'OpportunitÃ© Gap'
        ] + [f'Concurrent {i+1}' for i in range(len(other_competitors[:3]))]
        
        # Styling du tableau
        st.dataframe(
            display_df,
            use_container_width=True,
            height=600,
            column_config={
                "Score PrioritÃ©": st.column_config.ProgressColumn(
                    "Score PrioritÃ©",
                    help="Score calculÃ© sur 100",
                    min_value=0,
                    max_value=100,
                ),
                "DR": st.column_config.NumberColumn(
                    "DR",
                    help="Domain Rating Ahrefs",
                    min_value=0,
                    max_value=100,
                    format="%d",
                ),
                "Trafic": st.column_config.NumberColumn(
                    "Trafic",
                    help="Trafic mensuel estimÃ©",
                    format="%d",
                ),
            }
        )
        
        # Export des rÃ©sultats
        st.subheader("ğŸ’¾ Export des rÃ©sultats")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“„ TÃ©lÃ©charger le rapport complet (CSV)"):
                csv = filtered_df.to_csv(index=False)
                st.download_button(
                    label="â¬‡ï¸ TÃ©lÃ©charger CSV",
                    data=csv,
                    file_name=f"netlinking_analysis_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv"
                )
        
        with col2:
            top_n = st.selectbox("Nombre de top domaines Ã  exporter", [10, 20, 50, 100], index=1)
            if st.button(f"ğŸ“‹ TÃ©lÃ©charger Top {top_n}"):
                top_csv = filtered_df.head(top_n).to_csv(index=False)
                st.download_button(
                    label=f"â¬‡ï¸ TÃ©lÃ©charger Top {top_n}",
                    data=top_csv,
                    file_name=f"top_{top_n}_netlinking_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv"
                )
        
        # Analyse dÃ©taillÃ©e par segments
        st.subheader("ğŸ¯ Analyse par segments")
        
        # CrÃ©er des segments basÃ©s sur le score
        def categorize_priority(score):
            if score >= 70:
                return "ğŸ”¥ PrioritÃ© Maximale"
            elif score >= 50:
                return "âš¡ PrioritÃ© Ã‰levÃ©e"
            elif score >= 30:
                return "ğŸ¯ PrioritÃ© Moyenne"
            else:
                return "ğŸ“ PrioritÃ© Faible"
        
        filtered_df['priority_category'] = filtered_df['priority_score'].apply(categorize_priority)
        
        # Graphique en secteurs
        priority_counts = filtered_df['priority_category'].value_counts()
        fig_pie = px.pie(
            values=priority_counts.values,
            names=priority_counts.index,
            title="RÃ©partition des opportunitÃ©s par niveau de prioritÃ©"
        )
        st.plotly_chart(fig_pie, use_container_width=True)
        
        # Statistiques par segment
        stats_by_priority = filtered_df.groupby('priority_category').agg({
            'Domain rating': 'mean',
            'Domain traffic': 'mean',
            'competitor_links_count': 'mean',
            'Domain': 'count'
        }).round(2)
        
        stats_by_priority.columns = ['DR Moyen', 'Trafic Moyen', 'Gap Moyen', 'Nombre de Domaines']
        st.dataframe(stats_by_priority, use_container_width=True)
        
        # Recommandations automatiques
        st.subheader("ğŸ’¡ Recommandations automatiques")
        
        # Top 3 domaines prioritaires
        top_3 = filtered_df.head(3)
        
        st.write("**ğŸ† Top 3 des domaines Ã  contacter en prioritÃ© :**")
        for i, (_, domain) in enumerate(top_3.iterrows(), 1):
            with st.expander(f"#{i} - {domain['Domain']} (Score: {domain['priority_score']})"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("Domain Rating", f"{domain['Domain rating']}")
                    st.metric("Trafic mensuel", f"{domain['Domain traffic']:,.0f}")
                
                with col2:
                    st.metric("Concurrents liÃ©s", f"{domain['competitor_links_count']}")
                    st.metric("Potentiel trafic", f"{domain['traffic_potential']:,.0f}")
                
                # Afficher quels concurrents ont des liens
                linked_competitors = []
                for comp in other_competitors:
                    if pd.notna(domain[comp]) and int(domain[comp]) > 0:
                        linked_competitors.append(f"{comp} ({int(domain[comp])} liens)")
                
                if linked_competitors:
                    st.write("**Concurrents ayant des liens :**")
                    st.write(" â€¢ ".join(linked_competitors))
        
        # Analyse des gaps les plus importants
        st.write("**ğŸ¯ Analyse des gaps concurrentiels :**")
        
        high_gap_domains = filtered_df[filtered_df['competitor_links_count'] >= max_competitors - 1]
        if len(high_gap_domains) > 0:
            st.info(f"ğŸ“ˆ {len(high_gap_domains)} domaines font des liens vers {max_competitors - 1}+ concurrents mais pas vers vous !")
            
            gap_sample = high_gap_domains.head(5)[['Domain', 'Domain rating', 'competitor_links_count', 'priority_score']]
            st.dataframe(gap_sample, use_container_width=True)
        
        # Recommandations par DR
        high_dr_domains = filtered_df[filtered_df['Domain rating'] >= 70]
        if len(high_dr_domains) > 0:
            st.success(f"ğŸŒŸ {len(high_dr_domains)} domaines avec un DR Ã©levÃ© (70+) identifiÃ©s")
        
        medium_dr_domains = filtered_df[(filtered_df['Domain rating'] >= 40) & (filtered_df['Domain rating'] < 70)]
        if len(medium_dr_domains) > 0:
            st.warning(f"âš–ï¸ {len(medium_dr_domains)} domaines avec un DR moyen (40-70) - bon rapport effort/bÃ©nÃ©fice")

else:
    # Page d'accueil sans fichiers
    st.markdown("""
    ## ğŸš€ Comment utiliser cet outil ?
    
    ### ğŸ“‹ Ã‰tapes Ã  suivre :
    
    1. **Exportez vos donnÃ©es depuis Ahrefs :**
       - Allez dans l'outil "Link Intersect"
       - Ajoutez votre site + vos concurrents
       - Exportez les "Referring Domains" et "Referring Pages"
    
    2. **Exportez vos donnÃ©es depuis Google Search Console :**
       - Allez dans "Performances" > "RequÃªtes"
       - Exportez les donnÃ©es des requÃªtes et des pages
    
    3. **PrÃ©parez vos mots-clÃ©s stratÃ©giques :**
       - Format Excel ou CSV avec colonnes : Keyword, Search Volume, Keyword Difficulty
    
    4. **Uploadez tous les fichiers** dans la barre latÃ©rale
    
    5. **Configurez les filtres** selon vos besoins
    
    ### ğŸ¯ Ce que fait l'outil :
    
    - **Analyse les gaps concurrentiels** : Identifie les sites qui font des liens vers vos concurrents mais pas vers vous
    - **Calcule un score de prioritÃ©** basÃ© sur :
      - Domain Rating (20%)
      - Trafic du domaine (20%)  
      - Gap concurrentiel (30%)
      - Pertinence thÃ©matique (30%)
    - **Fournit des recommandations** pour optimiser vos campagnes de netlinking
    
    ### ğŸ“Š RÃ©sultats obtenus :
    
    - Tableau priorisÃ© des domaines Ã  contacter
    - Visualisations interactives
    - Export des rÃ©sultats en CSV
    - Recommandations automatiques
    - Analyse par segments de prioritÃ©
    
    **Commencez par uploader votre export Ahrefs "Referring Domains" dans la barre latÃ©rale !**
    """)
    
    # Afficher un exemple de structure attendue
    st.subheader("ğŸ“ Structure des fichiers attendus")
    
    with st.expander("Voir les formats de fichiers attendus"):
        st.markdown("""
        **Ahrefs - Referring Domains :**
        ```
        Domain | Domain rating | Domain traffic | Intersect | www.monsite.com | www.concurrent1.com | ...
        ```
        
        **GSC - RequÃªtes :**
        ```
        RequÃªtes les plus frÃ©quentes | Clics | Impressions | CTR | Position
        ```
        
        **GSC - Pages :**
        ```
        Pages les plus populaires | Clics | Impressions | CTR | Position
        ```
        
        **Mots-clÃ©s stratÃ©giques :**
        ```
        Keyword | Search Volume | Keyword Difficulty | CPC | ...
        ```
        """)

# Footer
st.markdown("---")
st.markdown("**DÃ©veloppÃ© pour optimiser vos campagnes de netlinking SEO** ğŸ¯")
